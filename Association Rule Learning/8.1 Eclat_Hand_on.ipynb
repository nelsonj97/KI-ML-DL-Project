{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eff4841",
   "metadata": {},
   "source": [
    "# Eclat model\n",
    "- The Eclat model is a simplified version of the **Apriori model**.\n",
    "- Can be built by adapting the Apriori model code\n",
    "- In Eclat we're not considering rule but set of items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68672fc",
   "metadata": {},
   "source": [
    "# 1. Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9499d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca32f23",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985621cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Here we only need to import the dataset.\n",
    "#### data_set = pd.read_csv('Market_Basket_Optimisation.csv')\n",
    "\n",
    "# 2. Since in the first row we don't have names of the columns, therefor we have to tell pandas that...\n",
    "# ... the first row does not contain the name of the columns, otherwise it will not consider the first row as data...\n",
    "# ... since it will think the first row are just name of columns. Here we've to set \"header = None\"\n",
    "data_set = pd.read_csv('Market_Basket_Optimisation.csv', header = None)\n",
    "\n",
    "# 3.0 When we will train the Apriori model on the dataset, we will use a certain function called apriori()....\n",
    "# ... which will take the dataset as an argument, but expect this dataset to have a certain format. ...\n",
    "# ... and that format is unfortunately not a pandas dataframe, therefore we have to recreate the dataset ...\n",
    "# ... from the original pandas dataframe, so that it can have this format expected by the apriori() function...\n",
    "# ... which will be used to train the Apriori model on the whole dataset. And this format is called \"lists of transactions\".\n",
    "\n",
    "# 3.1 1st step to create a list is to initialize the list as an empty list.\n",
    "transaction = []\n",
    "\n",
    "# 3.2 2nd step is to append the elements of the pandas dataframe to the list using a for loop...\n",
    "# ... 1st for loop will loop over the rows of the dataframe, 2nd for loop will loop over the 20 columns of the dataframe.\n",
    "for i in range(0, 7501):      # 7501 and not 7500 because the upper bound is excluded.\n",
    "                              # Each customer transaction must be stored as a list of product. i.e. in the end we're ....\n",
    "                              # ... creating  to have a list of lists.\n",
    "                              # i goes from 0 to 7501 and j from 0 to 20, because the upper bound is excluded \n",
    "    ### transaction.append(data_set.values[i, j] for j in range(0, 20) )   # values allows us to access the values of the dataframe.\n",
    "# 3.3 3rd step: In the Apriori Model all the element in the list must be strings, otherwise the model will not be able to learn\n",
    "# ... the rules. So the 3rd step is to convert the list of lists to a list of strings.\n",
    "    transaction.append([str(data_set.values[i, j]) for j in range(0, 20) ])\n",
    "# 3. Here we don't have to split the dataset into dependent and independent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53924f80",
   "metadata": {},
   "source": [
    "# 3. Training the Eclat model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa0eda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will use the Apyori Module to train the model and not scikit learn as usual.\n",
    "\n",
    "# 1. Importing the Apyori Module\n",
    "from apyori import apriori         # The apriori() function belong to the apyori module and will train the model...\n",
    "                                   # and return the rules i.e. support, confidence, lift that the model has learned.\n",
    "\n",
    "# 2. Training the Apriori Model on the dataset\n",
    "    # apriori() function takes 6 arguments: transactions, min_support, min_confidence, min_lift, min_length, max_length\n",
    "        # transaction is the dataset on which the apriori model will be trained and it value is our list i.e transaction.\n",
    "        # min_support number of times we should have at least one product in a transaction per week/day/month\n",
    "            # (Here we will like to consider the product that appears in at least 3 transaction in a day and (*7 days for a week))\n",
    "            # min_support = per day * 7 / (Total number of transactions) = 3*7/ 7501 = 0.003\n",
    "        # min_confidence: rule of thumb is 0.2\n",
    "        # min_lift: rule of thumb is at least 3\n",
    "        # Buy one product A and get another product B for free. Therefore the rule we want to get at the end must have only 2 products. ...\n",
    "            # ... i.e. one product in the left hand side of the rule and the other product in the right hand side of the rule.\n",
    "            # Therefore we need to add to more arguments min_length = 2 and max_length = 2\n",
    "            \n",
    "        # we kept the min_confidence = 0.2 and min_lift = 3 even though it's not needed because they will give us a strong association.\n",
    "rules = apriori(transactions = transaction, min_support = 0.003, min_confidence = 0.2, min_lift = 3, min_length = 2, max_length = 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09433d7b",
   "metadata": {},
   "source": [
    "# Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b015497",
   "metadata": {},
   "source": [
    "# 4. Displaying the first results coming directly from the output of the apriori function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f8c3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RelationRecord(items=frozenset({'light cream', 'chicken'}), support=0.004532728969470737, ordered_statistics=[OrderedStatistic(items_base=frozenset({'light cream'}), items_add=frozenset({'chicken'}), confidence=0.29059829059829057, lift=4.84395061728395)]),\n",
       " RelationRecord(items=frozenset({'escalope', 'mushroom cream sauce'}), support=0.005732568990801226, ordered_statistics=[OrderedStatistic(items_base=frozenset({'mushroom cream sauce'}), items_add=frozenset({'escalope'}), confidence=0.3006993006993007, lift=3.790832696715049)]),\n",
       " RelationRecord(items=frozenset({'escalope', 'pasta'}), support=0.005865884548726837, ordered_statistics=[OrderedStatistic(items_base=frozenset({'pasta'}), items_add=frozenset({'escalope'}), confidence=0.3728813559322034, lift=4.700811850163794)]),\n",
       " RelationRecord(items=frozenset({'fromage blanc', 'honey'}), support=0.003332888948140248, ordered_statistics=[OrderedStatistic(items_base=frozenset({'fromage blanc'}), items_add=frozenset({'honey'}), confidence=0.2450980392156863, lift=5.164270764485569)]),\n",
       " RelationRecord(items=frozenset({'ground beef', 'herb & pepper'}), support=0.015997866951073192, ordered_statistics=[OrderedStatistic(items_base=frozenset({'herb & pepper'}), items_add=frozenset({'ground beef'}), confidence=0.3234501347708895, lift=3.2919938411349285)]),\n",
       " RelationRecord(items=frozenset({'ground beef', 'tomato sauce'}), support=0.005332622317024397, ordered_statistics=[OrderedStatistic(items_base=frozenset({'tomato sauce'}), items_add=frozenset({'ground beef'}), confidence=0.3773584905660377, lift=3.840659481324083)]),\n",
       " RelationRecord(items=frozenset({'light cream', 'olive oil'}), support=0.003199573390214638, ordered_statistics=[OrderedStatistic(items_base=frozenset({'light cream'}), items_add=frozenset({'olive oil'}), confidence=0.20512820512820515, lift=3.1147098515519573)]),\n",
       " RelationRecord(items=frozenset({'olive oil', 'whole wheat pasta'}), support=0.007998933475536596, ordered_statistics=[OrderedStatistic(items_base=frozenset({'whole wheat pasta'}), items_add=frozenset({'olive oil'}), confidence=0.2714932126696833, lift=4.122410097642296)]),\n",
       " RelationRecord(items=frozenset({'pasta', 'shrimp'}), support=0.005065991201173177, ordered_statistics=[OrderedStatistic(items_base=frozenset({'pasta'}), items_add=frozenset({'shrimp'}), confidence=0.3220338983050847, lift=4.506672147735896)])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Display the result as a list\n",
    "results = list(rules)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd4bc1",
   "metadata": {},
   "source": [
    "# 5. Putting the results well organised into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd66f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since scrolling the above result left and right is overwhelming, we will display the result well organised into a pandas dataframe.\n",
    "\n",
    "def inspect(results):          # <= The insect() function will take the result of the apriori() function as an argument and will return the rules. ...\n",
    "                               # ...  we'll be able to sort the rule by a descending metric. In the above result they are not sorted.\n",
    "\n",
    "# In the 1st line of the above result, index 2 will access the 2nd element: index 0 of the 2nd element will be access and then use index 0 to access index the 0th element of lhs.\n",
    "# ordered_statistics=[OrderedStatistic(items_base=frozenset({'light cream'}), items_add=frozenset({'chicken'}), confidence=0.29059829059829057, lift=4.84395061728395)]\n",
    "    # items_base=frozenset({'light cream'}))\n",
    "    lhs         = [tuple(result[2][0][0])[0] for result in results]  # <= It will take as argument the product in the left hand side of the rule\n",
    "\n",
    "# In the 1st line of the above result, index 2 will access the 2nd element: we'll access the element of index 1 of the rhs and then use index 0 to access index the 0th element.\n",
    "# ordered_statistics=[OrderedStatistic(items_base=frozenset({'light cream'}), items_add=frozenset({'chicken'}), confidence=0.29059829059829057, lift=4.84395061728395)] \n",
    "    # items_add=frozenset({'chicken'}   \n",
    "    rhs         = [tuple(result[2][0][1])[0] for result in results]  # <= It will take as argument the product in the right hand side of the rule\n",
    "\n",
    "    supports    = [result[1] for result in results]                  # <= It will take as argument the support of all the rules\n",
    "\n",
    "    # In Eclat the confidence and lift are not needed therefore we have to remove them.\n",
    "    #### confidences = [result[2][0][2] for result in results]            # <= It will take as argument the confidence of all the rules\n",
    "    #### lifts       = [result[2][0][3] for result in results]            # <= It will take as argument the lift of all the rules\n",
    "    #### return list(zip(lhs, rhs, supports, confidences, lifts))         # <= It will return all the rules with rhs, lhs, supports, confidences and lifts in a list of tuples.\n",
    "\n",
    "    return list(zip(lhs, rhs, supports))  # <= It will return all the rules with rhs, lhs and supports in a list of tuples.\n",
    "# At the end we create a final Pandas dataframe  which take as input the output of the inspect() function. ...\n",
    "    # ... And beside we add the column names with 1st column = lhs, 2nd column = rhs, 3rd column = supports, 4th column = confidences, 5th column = lifts\n",
    "####resultsinDataFrame = pd.DataFrame(inspect(results), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])\n",
    "\n",
    "# Since the is no rule in the Eclat, we only consider product 1 and product 2, instead of left and right hand side as seen it the Apriori.\n",
    "resultsinDataFrame = pd.DataFrame(inspect(results), columns = ['Product 1', 'Product 2', 'Support'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fad1f",
   "metadata": {},
   "source": [
    "We have to display the result directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c251b2",
   "metadata": {},
   "source": [
    "# 6. Displaying the result sorted by descending support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b5c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Product 1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product 2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Support",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "dcfa610f-729f-4880-b13a-e60994c27e67",
       "rows": [
        [
         "4",
         "herb & pepper",
         "ground beef",
         "0.015997866951073192"
        ],
        [
         "7",
         "whole wheat pasta",
         "olive oil",
         "0.007998933475536596"
        ],
        [
         "2",
         "pasta",
         "escalope",
         "0.005865884548726837"
        ],
        [
         "1",
         "mushroom cream sauce",
         "escalope",
         "0.005732568990801226"
        ],
        [
         "5",
         "tomato sauce",
         "ground beef",
         "0.005332622317024397"
        ],
        [
         "8",
         "pasta",
         "shrimp",
         "0.005065991201173177"
        ],
        [
         "0",
         "light cream",
         "chicken",
         "0.004532728969470737"
        ],
        [
         "3",
         "fromage blanc",
         "honey",
         "0.003332888948140248"
        ],
        [
         "6",
         "light cream",
         "olive oil",
         "0.003199573390214638"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product 1</th>\n",
       "      <th>Product 2</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>herb &amp; pepper</td>\n",
       "      <td>ground beef</td>\n",
       "      <td>0.015998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>whole wheat pasta</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>0.007999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pasta</td>\n",
       "      <td>escalope</td>\n",
       "      <td>0.005866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushroom cream sauce</td>\n",
       "      <td>escalope</td>\n",
       "      <td>0.005733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tomato sauce</td>\n",
       "      <td>ground beef</td>\n",
       "      <td>0.005333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pasta</td>\n",
       "      <td>shrimp</td>\n",
       "      <td>0.005066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>light cream</td>\n",
       "      <td>chicken</td>\n",
       "      <td>0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fromage blanc</td>\n",
       "      <td>honey</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>light cream</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Product 1    Product 2   Support\n",
       "4         herb & pepper  ground beef  0.015998\n",
       "7     whole wheat pasta    olive oil  0.007999\n",
       "2                 pasta     escalope  0.005866\n",
       "1  mushroom cream sauce     escalope  0.005733\n",
       "5          tomato sauce  ground beef  0.005333\n",
       "8                 pasta       shrimp  0.005066\n",
       "0           light cream      chicken  0.004533\n",
       "3         fromage blanc        honey  0.003333\n",
       "6           light cream    olive oil  0.003200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. using a pre build function in pandas i.e. nlargest() to sort the result by descending order of lift\n",
    "resultsinDataFrame.nlargest(n = 10, columns = 'Support')         # n = number of rows we want to return i.e. display 10 rows with the highest support\n",
    "                                                                 # Column = by which column we want our result to be sorted.\n",
    "                                                                 # keep = whether we want to keep the index or not, incase we have duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba201e3",
   "metadata": {},
   "source": [
    "### Interpretation of the result for row 4 in the above table\n",
    "- Herb & pepper and ground beef are the set of 2 products that are purchase most frequently.\n",
    "  -  Since they have the highest support, it means that they are the most frequently purchased together.\n",
    "      - Their supports are 0.22, which means that these 2 products  appears in 22% of the transactions in the dataset.\n",
    "### and so on,.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
